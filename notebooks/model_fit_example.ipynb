{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_behavior_glm.glm import GLM\n",
    "import visual_behavior_glm.GLM_fit_tools as gft\n",
    "import visual_behavior_glm.GLM_analysis_tools as gat\n",
    "import visual_behavior_glm.GLM_visualization_tools as gvt\n",
    "\n",
    "import visual_behavior.utilities as vbu\n",
    "import visual_behavior.plotting as vbp\n",
    "import visual_behavior.data_access.loading as loading\n",
    "import visual_behavior.visualization.utils as vis_utils\n",
    "import visual_behavior.database as db\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied a custom magic command to make full use of screen width\n",
      "will only work if command is defined locally\n",
      "replace with the following to replicate functionality: \n",
      "\tfrom IPython.core.display import display, HTML\n",
      "\tdisplay(HTML(\"<style>.container { width:100% !important; }</style>\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "%widescreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing GLM_fit_tools from /allen/programs/braintv/workgroups/nc-ophys/visual_behavior/ophys_glm/v_8a_L2_optimize_by_session/frozen_model_files/GLM_fit_tools.py\n",
      "Fitting ophys_experiment_id: 990381322\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dougo/Code/AllenSDK/allensdk/brain_observatory/sync_dataset.py:109: UserWarning: The loaded sync file contains the following deprecated line label keys: {'cam2_exposure', 'cam1_exposure'}. Consider updating the sync file line labels.\n",
      "  self._check_line_labels()\n",
      "/home/dougo/Code/AllenSDK/allensdk/brain_observatory/sync_dataset.py:109: UserWarning: The loaded sync file contains the following deprecated line label keys: {'cam2_exposure', 'cam1_exposure'}. Consider updating the sync file line labels.\n",
      "  self._check_line_labels()\n",
      "WARNING:root:Could not find valid lines for the following data sources\n",
      "WARNING:root:acquiring (valid line label(s) = ['2p_acquiring']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing df/f data\n",
      "Build Design Matrix\n",
      "    Adding kernel: intercept\n",
      "    Adding kernel: time\n",
      "    Adding kernel: pre_licks\n",
      "Error encountered while adding kernel for pre_licks. Attemping to continue without this kernel. \n",
      "Less than minimum number of events: 0 licks\n",
      "    Adding kernel: post_licks\n",
      "Error encountered while adding kernel for post_licks. Attemping to continue without this kernel. \n",
      "Less than minimum number of events: 0 licks\n",
      "    Adding kernel: pre_lick_bouts\n",
      "Error encountered while adding kernel for pre_lick_bouts. Attemping to continue without this kernel. \n",
      "Less than minimum number of events: 0 lick_bouts\n",
      "    Adding kernel: post_lick_bouts\n",
      "Error encountered while adding kernel for post_lick_bouts. Attemping to continue without this kernel. \n",
      "Less than minimum number of events: 0 lick_bouts\n",
      "    Adding kernel: hits\n",
      "Error encountered while adding kernel for hits. Attemping to continue without this kernel. \n",
      "Less than minimum number of events: 0 hit\n",
      "    Adding kernel: misses\n",
      "    Adding kernel: false_alarms\n",
      "Error encountered while adding kernel for false_alarms. Attemping to continue without this kernel. \n",
      "Less than minimum number of events: 0 false_alarm\n",
      "    Adding kernel: correct_rejects\n",
      "    Adding kernel: omissions\n",
      "    Adding kernel: image_expectation\n",
      "    Adding kernel: running\n",
      "                 : Normalized by max value: 100\n",
      "    Adding kernel: pupil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dougo/Code/AllenSDK/allensdk/brain_observatory/sync_dataset.py:109: UserWarning: The loaded sync file contains the following deprecated line label keys: {'cam2_exposure', 'cam1_exposure'}. Consider updating the sync file line labels.\n",
      "  self._check_line_labels()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 : Mean Centering\n",
      "                 : Standardized to unit variance\n",
      "    Adding kernel: face_motion_PC_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:visual_behavior.ophys.sync.process_sync:Sync photodiode error needs to be fixed. Using assumed monitor delay: 0.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 : Mean Centering\n",
      "                 : Standardized to unit variance\n",
      "    Adding kernel: face_motion_PC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:visual_behavior.ophys.sync.process_sync:Sync photodiode error needs to be fixed. Using assumed monitor delay: 0.0351\n",
      "ERROR:visual_behavior.ophys.sync.process_sync:Sync photodiode error needs to be fixed. Using assumed monitor delay: 0.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 : Mean Centering\n",
      "                 : Standardized to unit variance\n",
      "    Adding kernel: face_motion_PC_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:visual_behavior.ophys.sync.process_sync:Sync photodiode error needs to be fixed. Using assumed monitor delay: 0.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 : Mean Centering\n",
      "                 : Standardized to unit variance\n",
      "    Adding kernel: face_motion_PC_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:visual_behavior.ophys.sync.process_sync:Sync photodiode error needs to be fixed. Using assumed monitor delay: 0.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 : Mean Centering\n",
      "                 : Standardized to unit variance\n",
      "    Adding kernel: face_motion_PC_4\n",
      "                 : Mean Centering\n",
      "                 : Standardized to unit variance\n",
      "    Adding kernel: image0\n",
      "    Adding kernel: image1\n",
      "    Adding kernel: image2\n",
      "    Adding kernel: image3\n",
      "    Adding kernel: image4\n",
      "    Adding kernel: image5\n",
      "    Adding kernel: image6\n",
      "    Adding kernel: image7\n",
      "    Adding kernel: model_bias\n",
      "Error encountered while adding kernel for model_bias. Attemping to continue without this kernel. \n",
      "[Errno 2] File b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv' does not exist: b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv'\n",
      "    Adding kernel: model_task0\n",
      "Error encountered while adding kernel for model_task0. Attemping to continue without this kernel. \n",
      "[Errno 2] File b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv' does not exist: b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv'\n",
      "    Adding kernel: model_omissions1\n",
      "Error encountered while adding kernel for model_omissions1. Attemping to continue without this kernel. \n",
      "[Errno 2] File b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv' does not exist: b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv'\n",
      "    Adding kernel: model_timing1D\n",
      "Error encountered while adding kernel for model_timing1D. Attemping to continue without this kernel. \n",
      "[Errno 2] File b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv' does not exist: b'/allen/programs/braintv/workgroups/nc-ophys/alex.piet/behavior/model_output/990207794.csv'\n",
      "The following kernels failed to be added to the model: \n",
      "{'post_lick_bouts', 'model_bias', 'model_omissions1', 'hits', 'model_task0', 'model_timing1D', 'pre_licks', 'false_alarms', 'pre_lick_bouts', 'post_licks'}\n",
      "The following dropouts failed to be added to the model: \n",
      "{'single-licking_each_lick', 'single-licking_bouts', 'single-hits', 'single-hits_and_rewards', 'single-post_licks', 'single-model_omissions1', 'single-model_bias', 'single-licking', 'single-model_task0', 'licking_each_lick', 'single-change_and_rewards', 'single-beh_model', 'licking_bouts', 'single-pre_licks', 'single-post_lick_bouts', 'licking', 'single-pre_lick_bouts', 'hits_and_rewards', 'single-model_timing1D', 'beh_model', 'change_and_rewards', 'single-false_alarms'}\n",
      "Setting up CV\n",
      "Evaluating Regularization values\n",
      "Using a hard-coded regularization value\n",
      "Setting up model selection dropout\n",
      "Iterating over model selection\n",
      "Using a constant regularization value across all cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Fitting model, Full: 100%|██████████| 5/5 [00:04<00:00,  1.24it/s]\n",
      "    Fitting model, intercept: 100%|██████████| 5/5 [00:08<00:00,  1.79s/it]\n",
      "    Fitting model, time: 100%|██████████| 5/5 [00:08<00:00,  1.77s/it]\n",
      "    Fitting model, misses: 100%|██████████| 5/5 [00:08<00:00,  1.61s/it]\n",
      "    Fitting model, correct_rejects: 100%|██████████| 5/5 [00:08<00:00,  1.62s/it]\n",
      "    Fitting model, omissions: 100%|██████████| 5/5 [00:08<00:00,  1.65s/it]\n",
      "    Fitting model, image_expectation: 100%|██████████| 5/5 [00:08<00:00,  1.72s/it]\n",
      "    Fitting model, running: 100%|██████████| 5/5 [00:08<00:00,  1.72s/it]\n",
      "    Fitting model, pupil: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "    Fitting model, face_motion_PC_0: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "    Fitting model, face_motion_PC_1: 100%|██████████| 5/5 [00:08<00:00,  1.71s/it]\n",
      "    Fitting model, face_motion_PC_2: 100%|██████████| 5/5 [00:08<00:00,  1.72s/it]\n",
      "    Fitting model, face_motion_PC_3: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "    Fitting model, face_motion_PC_4: 100%|██████████| 5/5 [00:08<00:00,  1.67s/it]\n",
      "    Fitting model, image0: 100%|██████████| 5/5 [00:08<00:00,  1.68s/it]\n",
      "    Fitting model, image1: 100%|██████████| 5/5 [00:08<00:00,  1.68s/it]\n",
      "    Fitting model, image2: 100%|██████████| 5/5 [00:08<00:00,  1.67s/it]\n",
      "    Fitting model, image3: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "    Fitting model, image4: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "    Fitting model, image5: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "    Fitting model, image6: 100%|██████████| 5/5 [00:08<00:00,  1.70s/it]\n",
      "    Fitting model, image7: 100%|██████████| 5/5 [00:08<00:00,  1.68s/it]\n",
      "    Fitting model, face_motion_energy: 100%|██████████| 5/5 [00:07<00:00,  1.53s/it]\n",
      "    Fitting model, all-images: 100%|██████████| 5/5 [00:07<00:00,  1.58s/it]\n",
      "    Fitting model, visual: 100%|██████████| 5/5 [00:07<00:00,  1.56s/it]\n",
      "    Fitting model, behavioral: 100%|██████████| 5/5 [00:07<00:00,  1.45s/it]\n",
      "    Fitting model, pupil_and_running: 100%|██████████| 5/5 [00:08<00:00,  1.62s/it]\n",
      "    Fitting model, pupil_and_omissions: 100%|██████████| 5/5 [00:08<00:00,  1.66s/it]\n",
      "    Fitting model, running_and_omissions: 100%|██████████| 5/5 [00:08<00:00,  1.62s/it]\n",
      "    Fitting model, task: 100%|██████████| 5/5 [00:07<00:00,  1.49s/it]\n",
      "    Fitting model, trial_type: 100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n",
      "    Fitting model, expectation: 100%|██████████| 5/5 [00:08<00:00,  1.65s/it]\n",
      "    Fitting model, cognitive: 100%|██████████| 5/5 [00:07<00:00,  1.49s/it]\n",
      "    Fitting model, single-time: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
      "    Fitting model, single-misses: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
      "    Fitting model, single-correct_rejects: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
      "    Fitting model, single-omissions: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
      "    Fitting model, single-image_expectation: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
      "    Fitting model, single-running: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Fitting model, single-pupil: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Fitting model, single-face_motion_PC_0: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Fitting model, single-face_motion_PC_1: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Fitting model, single-face_motion_PC_2: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Fitting model, single-face_motion_PC_3: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Fitting model, single-face_motion_PC_4: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Fitting model, single-image0: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "    Fitting model, single-image1: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
      "    Fitting model, single-image2: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "    Fitting model, single-image3: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
      "    Fitting model, single-image4: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "    Fitting model, single-image5: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
      "    Fitting model, single-image6: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "    Fitting model, single-image7: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "    Fitting model, single-face_motion_energy: 100%|██████████| 5/5 [00:06<00:00,  1.22s/it]\n",
      "    Fitting model, single-all-images: 100%|██████████| 5/5 [00:05<00:00,  1.18s/it]\n",
      "    Fitting model, single-visual: 100%|██████████| 5/5 [00:06<00:00,  1.22s/it]\n",
      "    Fitting model, single-behavioral: 100%|██████████| 5/5 [00:06<00:00,  1.33s/it]\n",
      "    Fitting model, single-pupil_and_running: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]\n",
      "    Fitting model, single-pupil_and_omissions: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\n",
      "    Fitting model, single-running_and_omissions: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]\n",
      "    Fitting model, single-task: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n",
      "    Fitting model, single-trial_type: 100%|██████████| 5/5 [00:06<00:00,  1.22s/it]\n",
      "    Fitting model, single-expectation: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n",
      "    Fitting model, single-cognitive: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]\n",
      "    Bootstrapping with 100 regressors:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting diagnostics\n",
      "Bootstrapping synthetic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Bootstrapping with 100 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n",
      "    Bootstrapping with 200 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]\n",
      "    Bootstrapping with 300 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
      "    Bootstrapping with 400 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
      "    Bootstrapping with 500 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
      "    Bootstrapping with 600 regressors: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n",
      "    Bootstrapping with 700 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
      "    Bootstrapping with 800 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "    Bootstrapping with 900 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]\n",
      "    Bootstrapping with 1000 regressors: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "    Shuffling by cells:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating shuffle fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Shuffling by cells: 100%|██████████| 50/50 [00:01<00:00, 34.77it/s]\n",
      "    Shuffling by time: 100%|██████████| 50/50 [00:01<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results\n",
      "Saving Design Matrix\n",
      "Saving Events Table\n",
      "Finished\n",
      "done fitting model, collecting results\n",
      "done collecting results\n",
      "logging results to mongo\n",
      "done logging results to mongo\n",
      "logging W matrix to mongo\n",
      "done logging W matrix to mongo\n",
      "done building GLM object\n"
     ]
    }
   ],
   "source": [
    "# oeid = 833629926 #slc example\n",
    "# oeid = 808621958 #vip example\n",
    "oeid = 990381322 #sst example\n",
    "version = '8a_L2_optimize_by_session'\n",
    "glm = GLM(oeid, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glm.results.sort_values(by='Full_avg_cv_var_test', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glm.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_specimen_id = glm.results.sort_values(by='Full_avg_cv_var_test', ascending=False).index[0]\n",
    "glm.plot_dropout_summary(cell_specimen_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movie = gvt.GLM_Movie(\n",
    "    glm,\n",
    "    cell_specimen_id = cell_specimen_id, \n",
    "    start_frame = 39400,\n",
    "    end_frame = 39500\n",
    ")\n",
    "# \"\"\n",
    "movie.make_cell_movie_frame(movie.ax, movie.glm, 20000, movie.cell_specimen_id, t_before=10, t_after=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glm.plot_filters(cell_specimen_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gft.L2_report(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit['regularization'] = np.mean([fit['L2_grid'][x] for x in np.argmax(test_cv,1)])      \n",
    "#         fit['L2_test_cv'] = test_cv\n",
    "#         fit['L2_train_cv'] = train_cv\n",
    "glm.fit['regularization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cv = glm.fit['L2_test_cv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.argmax(test_cv,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = glm.fit\n",
    "test_cv = glm.fit['L2_test_cv']\n",
    "lambdas = [fit['L2_grid'][x] for x in np.argmax(test_cv,1)]\n",
    "fig,ax=plt.subplots()\n",
    "ax.hist(lambdas,bins=np.arange(0,525,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 2\n",
    "(lam * np.eye(glm.X.shape[-1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "licks = glm.session.dataset.licks\n",
    "licks['time_to_last_lick'] = licks['timestamps'] - licks['timestamps'].shift()\n",
    "licks['first_in_bout'] = licks['time_to_last_lick'] > 2\n",
    "licks['first_in_bout'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_kernel = glm.W.loc[dict(weights=kernel_weight_names, cell_specimen_id=cell_specimen_id)]\n",
    "w_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(w_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = glm.session\n",
    "session.dataset.trials.query('correct_reject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'hit'\n",
    "if event in ['hit','miss']:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual_behavior",
   "language": "python",
   "name": "visual_behavior"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
